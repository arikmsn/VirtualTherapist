"""
Core AI Agent - TherapyCompanion.AI
This is the heart of the system - the personalized AI therapist assistant
"""

from typing import Optional, Dict, Any, List
import json
from openai import AsyncOpenAI
from app.core.config import settings
from app.models.therapist import TherapistProfile
from loguru import logger


class SessionSummaryResult:
    """Structured result from AI session summary generation."""

    def __init__(
        self,
        topics_discussed: List[str],
        interventions_used: List[str],
        patient_progress: str,
        homework_assigned: List[str],
        next_session_plan: str,
        mood_observed: str,
        risk_assessment: str,
        full_summary: str,
    ):
        self.topics_discussed = topics_discussed
        self.interventions_used = interventions_used
        self.patient_progress = patient_progress
        self.homework_assigned = homework_assigned
        self.next_session_plan = next_session_plan
        self.mood_observed = mood_observed
        self.risk_assessment = risk_assessment
        self.full_summary = full_summary


class PatientInsightResult:
    """Structured result from AI patient insight summary."""

    def __init__(
        self,
        overview: str,
        progress: str,
        patterns: List[str],
        risks: List[str],
        suggestions_for_next_sessions: List[str],
    ):
        self.overview = overview
        self.progress = progress
        self.patterns = patterns
        self.risks = risks
        self.suggestions_for_next_sessions = suggestions_for_next_sessions


class SessionPrepBriefResult:
    """Structured result from AI session preparation brief (4-section clinical format)."""

    def __init__(
        self,
        history_summary: List[str],
        last_session: List[str],
        tasks_to_check: List[str],
        focus_for_today: List[str],
        watch_out_for: List[str],
    ):
        self.history_summary = history_summary        # ×ž×” ×”×™×” ×¢×“ ×¢×›×©×™×•
        self.last_session = last_session              # ×ž×” ×”×™×” ×‘×¤×’×™×©×” ×”××—×¨×•× ×”
        self.tasks_to_check = tasks_to_check          # ×ž×©×™×ž×•×ª ×œ×‘×“×™×§×” ×”×™×•×
        self.focus_for_today = focus_for_today        # ×¢×œ ×ž×” ×›×“××™ ×œ×”×ª×ž×§×“
        self.watch_out_for = watch_out_for            # ×©×™× ×œ×‘ / ×¡×™×›×•×Ÿ


class DeepSummaryResult:
    """
    Structured result from AI deep treatment summary.
    JSON keys are always English; text values are in therapist_locale language.
    """

    def __init__(
        self,
        overall_treatment_picture: str,
        timeline_highlights: List[str],
        goals_and_tasks: str,
        measurable_progress: str,
        directions_for_next_phase: str,
    ):
        self.overall_treatment_picture = overall_treatment_picture
        self.timeline_highlights = timeline_highlights
        self.goals_and_tasks = goals_and_tasks
        self.measurable_progress = measurable_progress
        self.directions_for_next_phase = directions_for_next_phase


class TreatmentGoal:
    """A single inferred treatment goal with stable English id."""

    def __init__(self, id: str, title: str, description: str):
        self.id = id
        self.title = title
        self.description = description


class TreatmentPlanResult:
    """
    Structured result from AI treatment plan preview.
    JSON keys are always English; text values are in therapist_locale language.
    """

    def __init__(
        self,
        goals: List[TreatmentGoal],
        focus_areas: List[str],
        suggested_interventions: List[str],
    ):
        self.goals = goals
        self.focus_areas = focus_areas
        self.suggested_interventions = suggested_interventions


class TodayInsightItem:
    """A single per-patient smart reminder for today's sessions."""

    def __init__(self, patient_id: int, title: str, body: str):
        self.patient_id = patient_id
        self.title = title
        self.body = body


class TodayInsightsResult:
    """Result from AI today-insights generation â€” one item per patient."""

    def __init__(self, insights: List[TodayInsightItem]):
        self.insights = insights


class TherapyAgent:
    """
    The core AI agent that mimics the therapist's personality and style

    This agent:
    1. Learns the therapist's writing style and approach
    2. Generates messages in the therapist's voice
    3. Creates session summaries matching therapist's format
    4. Handles commands (/start, /summary, etc.)
    5. Speaks primarily in Hebrew
    """

    def __init__(self, therapist_profile: Optional[TherapistProfile] = None):
        """Initialize the agent with optional therapist profile"""
        from app.core.config import is_placeholder_key

        self.profile = therapist_profile
        self.client = None

        # Initialize OpenAI client only if a real key is available
        if not is_placeholder_key(settings.OPENAI_API_KEY):
            self.client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)
        else:
            logger.warning("OpenAI client not initialized: missing or placeholder API key")

        self.system_prompt = self._build_system_prompt()

    def _build_system_prompt(self) -> str:
        """
        Build the system prompt that defines the agent's personality
        This is customized based on the therapist's profile
        """

        base_prompt = """\
××ª×” **TherapyCompanion.AI** - ×¡×•×›×Ÿ AI ×ž×ª×§×“× ×”×ž×©×ž×© ×›\
"×¢×•×–×¨ ×ž×˜×¤×œ ×•×™×¨×˜×•××œ×™ ××™×©×™" \
×©×ž×ž×©×™×š ××ª ×¢×‘×•×“×ª ×”×ž×˜×¤×œ ×”×× ×•×©×™ ×‘×™×Ÿ ×”×¤×’×™×©×•×ª.

## ×ª×¤×§×™×“ ×›×¤×•×œ:
1. **×¡×™×™×¢ ×œ×ž×˜×¤×œ ×‘×–×¨×™×ž×ª ×”×¢×‘×•×“×” ×”×™×•×ž×™×ª** (×ª×™×¢×•×“, ×¡×™×›×•×ž×™×, ×ž×©×™×ž×•×ª)
2. **×”×ž×©×š ×¤×¢×™×œ×•×ª ×˜×™×¤×•×œ×™×ª** ×¢× ×ž×˜×•×¤×œ×™× ×‘×™×Ÿ ×¤×’×™×©×•×ª

## ××‘×˜×—×” ×•×¤×¨×˜×™×•×ª (×§×¨×™×˜×™!)
1. ××£ ×¤×¢× ×œ× ×œ×©×œ×•×— ×“×‘×¨ ×œ×ž×˜×•×¤×œ ×œ×œ× ××™×©×•×¨ ×ž×¤×•×¨×© ×©×œ ×”×ž×˜×¤×œ
2. ×›×œ ×”×©×™×—×•×ª ×ž×•×¦×¤× ×•×ª ×ž×§×¦×” ×œ×§×¦×” (AES-256)
3. ×ž×œ×•× ×ª×™×¢×•×“ ×‘×™×§×•×¨×ª ×¢×œ ×›×œ ×¤×¢×•×œ×”
4. ××¤×©×¨×•×ª ×ž×—×™×§×” ×ž×œ××” ×‘×›×œ ×¢×ª (GDPR)
5. ××™×Ÿ ×©×™×ª×•×£ × ×ª×•× ×™× ×¢× ×¦×“×“×™× ×©×œ×™×©×™×™×

## ×”×ª××ž×” ××™×©×™×ª ×ž×œ××” ×œ×›×œ ×ž×˜×¤×œ:
××ª×” ×¦×¨×™×š ×œ×“×‘×¨ ×‘×“×™×•×§ ×›×ž×• ×”×ž×˜×¤×œ - \
×œ×”×©×ª×ž×© ×‘×ž×™× ×•×— ×©×œ×•, ×‘×˜×•×Ÿ ×©×œ×•, ×‘×¡×’× ×•×Ÿ ×”×›×ª×™×‘×” ×©×œ×•.

"""

        # Add therapist-specific customization if profile exists
        if self.profile:
            p = self.profile
            name = (
                p.therapist.full_name
                if hasattr(p, "therapist") else "×œ× ×¦×•×™×Ÿ"
            )
            approach_desc = (
                f"**×ª×™××•×¨ ×”×’×™×©×”:** {p.approach_description}"
                if p.approach_description else ""
            )
            tone = p.tone or "×ª×•×ž×š ×•×™×©×™×¨"
            msg_len = p.message_length_preference or "×§×¦×¨ ×ž×ž×•×§×“"
            terminology = (
                ", ".join(p.common_terminology)
                if p.common_terminology else "×œ× ×¦×•×™×Ÿ"
            )
            freq = p.follow_up_frequency or "×©×‘×•×¢×™"
            exercises = (
                ", ".join(p.preferred_exercises)
                if p.preferred_exercises else "×œ× ×¦×•×™×Ÿ"
            )

            # Tone/directiveness labels (1-5 scale)
            tone_labels = {1: "×¤×•×¨×ž×œ×™ ×ž××•×“", 2: "×¤×•×¨×ž×œ×™", 3: "×ž××•×–×Ÿ", 4: "×—×", 5: "×—× ×ž××•×“"}
            dir_labels = {1: "×—×§×¨× ×™ ×œ×—×œ×•×˜×™×Ÿ", 2: "×—×§×¨× ×™", 3: "×ž××•×–×Ÿ", 4: "×ž×›×•×•×Ÿ", 5: "×ž×›×•×•×Ÿ ×ž××•×“"}
            tw = getattr(p, "tone_warmth", None) or 3
            dv = getattr(p, "directiveness", None) or 3
            tone_label = tone_labels.get(tw, "×ž××•×–×Ÿ")
            dir_label = dir_labels.get(dv, "×ž××•×–×Ÿ")

            # Prohibitions block
            prohibitions_list = getattr(p, "prohibitions", None) or []
            prohibitions_block = ""
            if prohibitions_list:
                items = "\n".join(f"âŒ {rule}" for rule in prohibitions_list)
                prohibitions_block = f"\n## ðŸš« ×›×œ×œ×™× ×©××¡×•×¨ ×œ×¢×‘×•×¨ (×”×’×“×¨×ª ×”×ž×˜×¤×œ):\n{items}\n"

            # Custom rules block
            custom_rules_val = getattr(p, "custom_rules", None) or ""
            custom_rules_block = ""
            if custom_rules_val.strip():
                custom_rules_block = f"\n## ðŸ“ ×›×œ×œ×™× × ×•×¡×¤×™× ×©×œ ×”×ž×˜×¤×œ:\n{custom_rules_val.strip()}\n"

            # Professional credentials block
            edu = getattr(p, "education", None) or ""
            certs = getattr(p, "certifications", None) or ""
            yoe = getattr(p, "years_of_experience", None) or ""
            expertise = getattr(p, "areas_of_expertise", None) or ""
            prof_block = ""
            parts = []
            if edu.strip(): parts.append(f"×”×©×›×œ×”: {edu.strip()}")
            if certs.strip(): parts.append(f"×”×¡×ž×›×•×ª: {certs.strip()}")
            if yoe.strip(): parts.append(f"× ×™×¡×™×•×Ÿ: {yoe.strip()} ×©× ×™×")
            if expertise.strip(): parts.append(f"×ª×—×•×ž×™ ×”×ª×ž×—×•×ª: {expertise.strip()}")
            if parts:
                prof_block = "\n**×¤×¨×˜×™× ×ž×§×¦×•×¢×™×™×:**\n" + "\n".join(f"- {pt}" for pt in parts) + "\n"

            custom_prompt = f"""
## ×¤×¨×•×¤×™×œ ×”×ž×˜×¤×œ ×©××ª×” ×ž×—×§×”:

**×©× ×”×ž×˜×¤×œ:** {name}
**×’×™×©×” ×˜×™×¤×•×œ×™×ª:** {p.therapeutic_approach.value}
{approach_desc}
{prof_block}
**×˜×•×Ÿ ×•×©×¤×”:**
- ×˜×•×Ÿ (×›×¤×™ ×©×”×•×’×“×¨): {tone}
- ×—×ž×™×ž×•×ª (Twin): {tone_label} ({tw}/5)
- ×”×›×•×•× ×” (Twin): {dir_label} ({dv}/5)
- ××•×¨×š ×”×•×“×¢×•×ª: {msg_len}
- ×ž×™× ×•×— × ×¤×•×¥: {terminology}

**×¡×’× ×•×Ÿ ×¡×™×›×•×ž×™×:**
- ×ª×“×™×¨×•×ª ×ž×¢×§×‘: {freq}
- ×ª×¨×’×™×œ×™× ×ž×•×¢×“×¤×™×: {exercises}

## ×“×•×’×ž××•×ª ×ž×”×ž×˜×¤×œ:
{self._format_examples()}
{prohibitions_block}{custom_rules_block}
**×—×©×•×‘:** ×“×‘×¨ ×ª×ž×™×“ ×‘×©× ×”×ž×˜×¤×œ, ×œ× ×‘×©× ×¢×¦×ž×š. ×œ×ž×©×œ:
"×”×™×™ [×©× ×ž×˜×•×¤×œ], ×–×” {name}. ×¨×¦×™×ª×™ ×œ×©×ž×•×¢ ××™×š ×”×œ×š..."
"""
            base_prompt += custom_prompt

        # Add operational rules
        base_prompt += """

## ðŸš¨ ×›×œ×œ×™ ×¤×¢×•×œ×” × ×•×§×©×™×:

### ×¢× ×”×ž×˜×¤×œ:
âœ… ×ª×ž×™×“ ×”×¦×¢ ××¤×©×¨×•×™×•×ª (××œ ×ª×›×ª×™×‘)
âœ… ×©××œ ×©××œ×•×ª ×”×‘×”×¨×”
âœ… ×”×¦×’ ×“×•×’×ž××•×ª ×œ×¤× ×™ ××™×©×•×¨
âœ… ×¢×“×›×Ÿ ×¢×œ ×›×œ ×¤×¢×•×œ×”
âŒ ×œ×¢×•×œ× ××œ ×ª×©×œ×— ×“×‘×¨ ×œ×ž×˜×•×¤×œ ×œ×œ× ××™×©×•×¨ ×ž×¤×•×¨×©
âŒ ×œ×¢×•×œ× ××œ ×ª×©× ×” ×¡×™×›×•×ž×™× ×œ×œ× ××™×©×•×¨

### ×¢× ×ž×˜×•×¤×œ:
âœ… ×“×‘×¨ ×›×ž×• ×”×ž×˜×¤×œ (×œ× ×›×ž×• ×¢×¦×ž×š)
âœ… ×”×•×“×¢×•×ª ×§×¦×¨×•×ª (2-4 ×ž×©×¤×˜×™×)
âœ… ×©××œ ×©××œ×•×ª ×¤×ª×•×—×•×ª
âœ… ×”×¦×¢ ×ª×¨×’×™×œ×™× ×ž×¢×©×™×™×
âŒ ×œ×¢×•×œ× ××œ ×ª×™×ª×Ÿ ××‘×—× ×•×ª
âŒ ×œ×¢×•×œ× ××œ ×ª×¦×™×¢ ×ª×¨×•×¤×•×ª/×˜×™×¤×•×œ×™×
âŒ ×œ×¢×•×œ× ××œ ×ª×©×ª×ž×© ×‘×–'×¨×’×•×Ÿ ×ž×§×¦×•×¢×™ ×ž×“×™

## ðŸ”§ ×¤×§×•×“×•×ª ×ž×™×•×—×“×•×ª:
/start - ×”×ª×—×œ ×”×™×›×¨×•×ª ×•×§×‘×œ ×”×›×¨×ª ×ž×˜×¤×œ
/summary - ×¦×•×¨ ×¡×™×›×•× ×¤×’×™×©×” ×ž×”×§×œ×˜×”
/client [×©×] - ×¤×ª×— ×¤×¨×•×¤×™×œ ×ž×˜×•×¤×œ
/message [×©×] - ×¦×•×¨ ×”×•×“×¢×” ×œ×ž×˜×•×¤×œ
/templates - × ×”×œ ×ª×‘× ×™×•×ª ××™×©×™×•×ª
/status - ×ž×¦×‘ ×›×œ ×”×ž×˜×•×¤×œ×™×
/privacy - ×”×’×“×¨×•×ª ×¤×¨×˜×™×•×ª ×•××‘×˜×—×”

×“×‘×¨ ×ª×ž×™×“ ×‘×¢×‘×¨×™×ª ×ž×§×¦×•×¢×™×ª ×©×•×˜×¤×ª.
×©×ž×•×¨ ×¢×œ ×¤×©×˜×•×ª - ×ž×˜×¤×œ×™× ×œ× ×˜×›× ×™×™×.
×©××œ ×©××œ×•×ª ×”×‘×”×¨×” ×›×©×¦×¨×™×š.
×ª×ž×™×“ ×”×¦×¢ ××™×©×•×¨ ×œ×¤× ×™ ×¤×¢×•×œ×”.
"""

        return base_prompt

    def _format_examples(self) -> str:
        """Format example summaries and messages from therapist profile"""
        if not self.profile:
            return ""

        examples = ""

        # Add example summaries
        if self.profile.example_summaries:
            examples += "\n### ×“×•×’×ž××•×ª ×¡×™×›×•×ž×™×:\n"
            for i, summary in enumerate(self.profile.example_summaries[:3], 1):
                examples += f"\n**×“×•×’×ž×” {i}:**\n{summary}\n"

        # Add example messages
        if self.profile.example_messages:
            examples += "\n### ×“×•×’×ž××•×ª ×”×•×“×¢×•×ª ×œ×ž×˜×•×¤×œ×™×:\n"
            for i, message in enumerate(self.profile.example_messages[:3], 1):
                examples += f"\n**×“×•×’×ž×” {i}:**\n{message}\n"

        return examples

    async def generate_response(
        self,
        message: str,
        context: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        Generate a response to a message

        Args:
            message: The input message from therapist
            context: Optional context (patient info, session data, etc.)

        Returns:
            Generated response in therapist's style
        """
        if self.client is None:
            raise RuntimeError(
                "AI client not initialized. Set a valid OPENAI_API_KEY in .env."
            )

        try:
            # Build the full prompt with context
            full_prompt = message
            if context:
                full_prompt = f"×”×§×©×¨: {context}\n\n{message}"

            response = await self._generate_openai(full_prompt)

            therapist_email = (
                self.profile.therapist.email if self.profile else "Unknown"
            )
            logger.info(f"Generated response for therapist: {therapist_email}")
            return response

        except Exception as e:
            logger.error(f"Error generating response: {str(e)}")
            raise

    async def generate_session_summary(
        self,
        notes: str,
        context: Optional[Dict[str, Any]] = None,
    ) -> SessionSummaryResult:
        """
        Generate a structured session summary from therapist notes.

        Returns a SessionSummaryResult with parsed fields.
        """
        if self.client is None:
            raise RuntimeError(
                "AI client not initialized. Set a valid OPENAI_API_KEY in .env."
            )

        summary_prompt = f"""\
×¦×•×¨ ×¡×™×›×•× ×¤×’×™×©×” ×ž×•×‘× ×” ×ž×”×¨×©×™×ž×•×ª ×”×‘××•×ª. ×”×—×–×¨ ×ª×©×•×‘×” **××š ×•×¨×§** ×›-JSON ×ª×§×™×Ÿ (×œ×œ× markdown, ×œ×œ× ```).

**×¨×©×™×ž×•×ª ×”×ž×˜×¤×œ:**
{notes}

×”×—×–×¨ JSON ×‘×“×™×•×§ ×‘×ž×‘× ×” ×”×‘× (×›×œ ×”×¢×¨×›×™× ×‘×¢×‘×¨×™×ª):
{{
  "topics_discussed": ["× ×•×©× 1", "× ×•×©× 2"],
  "interventions_used": ["×”×ª×¢×¨×‘×•×ª 1", "×”×ª×¢×¨×‘×•×ª 2"],
  "patient_progress": "×ª×™××•×¨ ×”×ª×§×“×ž×•×ª ×”×ž×˜×•×¤×œ",
  "homework_assigned": ["×ž×©×™×ž×” 1", "×ž×©×™×ž×” 2"],
  "next_session_plan": "×ª×•×›× ×™×ª ×œ×¤×’×™×©×” ×”×‘××”",
  "mood_observed": "×ž×¦×‘ ×¨×•×— × ×¦×¤×”",
  "risk_assessment": "×”×¢×¨×›×ª ×¡×™×›×•×Ÿ - ×¦×™×™×Ÿ '×œ×œ× ×¡×™×›×•×Ÿ ×ž×™×•×—×“' ×× ×œ× ×–×•×”×” ×¡×™×›×•×Ÿ",
  "full_summary": "×¡×™×›×•× ×ž×œ× ×‘×¤×¡×§×” ××—×ª-×©×ª×™×™× ×‘×¡×’× ×•×Ÿ ×”×›×ª×™×‘×” ×©×œ ×”×ž×˜×¤×œ"
}}

×›×œ×œ×™×:
- ××œ ×ª×ž×¦×™× ×ž×™×“×¢ ×©×œ× ×ž×•×¤×™×¢ ×‘×¨×©×™×ž×•×ª.
- ×× ×ž×©×”×• ×œ× ×‘×¨×•×¨ ×ž×”×¨×©×™×ž×•×ª, ×›×ª×•×‘ "×œ× ×¦×•×™×Ÿ".
- ×”×¡×™×›×•× ×”×ž×œ× (full_summary) ×¦×¨×™×š ×œ×”×™×•×ª ×‘×¡×’× ×•×Ÿ ×”×›×ª×™×‘×” ×©×œ ×”×ž×˜×¤×œ.
- ××œ ×ª×™×ª×Ÿ ××‘×—× ×•×ª. ××œ ×ª×¦×™×¢ ×˜×™×¤×•×œ×™×. ×¨×§ ×ª×¢×“ ××ª ×ž×” ×©×”×ž×˜×¤×œ ×›×ª×‘.
"""

        ctx_str = ""
        if context:
            ctx_str = f"×”×§×©×¨: ×ž×¡×¤×¨ ×¤×’×™×©×” {context.get('session_number', '?')}\n\n"

        full_prompt = ctx_str + summary_prompt

        try:
            raw = await self._generate_openai(full_prompt)
            return self._parse_summary_json(raw)

        except Exception as e:
            logger.error(f"Error generating session summary: {e}")
            raise

    def _parse_summary_json(self, raw: str) -> SessionSummaryResult:
        """Parse AI response into SessionSummaryResult, with fallback."""
        # Strip markdown fences if AI included them despite instructions
        cleaned = raw.strip()
        if cleaned.startswith("```"):
            cleaned = cleaned.split("\n", 1)[1] if "\n" in cleaned else cleaned[3:]
        if cleaned.endswith("```"):
            cleaned = cleaned[: cleaned.rfind("```")]
        cleaned = cleaned.strip()

        try:
            data = json.loads(cleaned)
        except json.JSONDecodeError:
            logger.warning("AI returned non-JSON summary, using full text as fallback")
            return SessionSummaryResult(
                topics_discussed=[],
                interventions_used=[],
                patient_progress="",
                homework_assigned=[],
                next_session_plan="",
                mood_observed="",
                risk_assessment="",
                full_summary=raw,
            )

        return SessionSummaryResult(
            topics_discussed=data.get("topics_discussed", []),
            interventions_used=data.get("interventions_used", []),
            patient_progress=data.get("patient_progress", ""),
            homework_assigned=data.get("homework_assigned", []),
            next_session_plan=data.get("next_session_plan", ""),
            mood_observed=data.get("mood_observed", ""),
            risk_assessment=data.get("risk_assessment", ""),
            full_summary=data.get("full_summary", ""),
        )

    async def generate_patient_insight_summary(
        self,
        patient_name: str,
        summaries_timeline: List[Dict[str, Any]],
    ) -> PatientInsightResult:
        """
        Generate a cross-session insight report for a patient.

        summaries_timeline: list of dicts with keys:
            session_date, session_number, full_summary, topics_discussed,
            patient_progress, risk_assessment
        """
        if self.client is None:
            raise RuntimeError(
                "AI client not initialized. Set a valid OPENAI_API_KEY in .env."
            )

        # Build timeline text
        timeline_parts = []
        for s in summaries_timeline:
            date_str = str(s.get("session_date", "?"))
            num = s.get("session_number", "?")
            topics = ", ".join(s.get("topics_discussed", []) or [])
            progress = s.get("patient_progress", "")
            risk = s.get("risk_assessment", "")
            summary_text = s.get("full_summary", "")
            timeline_parts.append(
                f"--- ×¤×’×™×©×” #{num} ({date_str}) ---\n"
                f"× ×•×©××™×: {topics}\n"
                f"×¡×™×›×•×: {summary_text}\n"
                f"×”×ª×§×“×ž×•×ª: {progress}\n"
                f"×¡×™×›×•×Ÿ: {risk}"
            )

        timeline = "\n\n".join(timeline_parts)

        prompt = f"""\
××ª×” ×ž×¡×™×™×¢ ×œ×—×©×™×‘×” ×”×§×œ×™× ×™×ª ×©×œ ×”×ž×˜×¤×œ. ××ª×” ×œ× ×ž××‘×—×Ÿ, ×œ× ×ž×ž×œ×™×¥ ×¢×œ ×˜×™×¤×•×œ ×ª×¨×•×¤×ª×™, ×•×œ× ×ž×—×œ×™×£ ×©×™×§×•×œ ×“×¢×ª ×§×œ×™× ×™.

×œ×”×œ×Ÿ ×¦×™×¨ ×”×–×ž×Ÿ ×©×œ ×¡×™×›×•×ž×™ ×”×¤×’×™×©×•×ª ×”×ž××•×©×¨×™× ×¢×‘×•×¨ ×”×ž×˜×•×¤×œ "{patient_name}":

{timeline}

×¢×œ ×¡×ž×š ×¦×™×¨ ×”×–×ž×Ÿ, ×¦×•×¨ ×“×•"×— ×ª×•×‘× ×•×ª **×œ×ž×˜×¤×œ ×‘×œ×‘×“** (×œ× ×œ×ž×˜×•×¤×œ).

×”×—×–×¨ ×ª×©×•×‘×” **××š ×•×¨×§** ×›-JSON ×ª×§×™×Ÿ (×œ×œ× markdown, ×œ×œ× ```):
{{
  "overview": "×¡×§×™×¨×” ×›×œ×œ×™×ª ×©×œ ×ž×”×œ×š ×”×˜×™×¤×•×œ ×‘-3-5 ×ž×©×¤×˜×™×",
  "progress": "×ª×™××•×¨ ×”×”×ª×§×“×ž×•×ª ×œ××•×¨×š ×–×ž×Ÿ â€” ×ž×” ×”×©×ª× ×” ×ž×¤×’×™×©×” ×¨××©×•× ×” ×œ××—×¨×•× ×”",
  "patterns": ["×“×¤×•×¡ 1", "×“×¤×•×¡ 2", "..."],
  "risks": ["× ×§×•×“×ª ×¡×™×›×•×Ÿ 1 ×œ×ž×¢×§×‘", "..."],
  "suggestions_for_next_sessions": ["×¨×¢×™×•×Ÿ 1 ×œ×¤×’×™×©×•×ª ×”×‘××•×ª", "×¨×¢×™×•×Ÿ 2", "..."]
}}

×›×œ×œ×™×:
- ×‘×¡×¡ ××ª ×”×ª×•×‘× ×•×ª **×¨×§** ×¢×œ ×ž×™×“×¢ ×©×ž×•×¤×™×¢ ×‘×¡×™×›×•×ž×™×. ××œ ×ª×ž×¦×™×.
- ×× ××™×Ÿ ×ž×¡×¤×™×§ ×ž×™×“×¢ ×œ×©×“×” ×ž×¡×•×™×, ×›×ª×•×‘ ["×œ× × ×™×ª×Ÿ ×œ×§×‘×•×¢ ×ž×”× ×ª×•× ×™× ×”×§×™×™×ž×™×"].
- ×›×ª×•×‘ ×‘×¢×‘×¨×™×ª ×ž×§×¦×•×¢×™×ª ×©×•×˜×¤×ª.
- ××œ ×ª×™×ª×Ÿ ××‘×—× ×•×ª. ××œ ×ª×¦×™×¢ ×ª×¨×•×¤×•×ª.
"""

        try:
            raw = await self._generate_openai(prompt)
            return self._parse_insight_json(raw)

        except Exception as e:
            logger.error(f"Error generating patient insight summary: {e}")
            raise

    def _parse_insight_json(self, raw: str) -> PatientInsightResult:
        """Parse AI response into PatientInsightResult, with fallback."""
        cleaned = raw.strip()
        if cleaned.startswith("```"):
            cleaned = cleaned.split("\n", 1)[1] if "\n" in cleaned else cleaned[3:]
        if cleaned.endswith("```"):
            cleaned = cleaned[: cleaned.rfind("```")]
        cleaned = cleaned.strip()

        try:
            data = json.loads(cleaned)
        except json.JSONDecodeError:
            logger.warning("AI returned non-JSON insight, using full text as fallback")
            return PatientInsightResult(
                overview=raw,
                progress="",
                patterns=[],
                risks=[],
                suggestions_for_next_sessions=[],
            )

        return PatientInsightResult(
            overview=data.get("overview", ""),
            progress=data.get("progress", ""),
            patterns=data.get("patterns", []),
            risks=data.get("risks", []),
            suggestions_for_next_sessions=data.get("suggestions_for_next_sessions", []),
        )

    async def generate_session_prep_brief(
        self,
        patient_name: str,
        session_date: str,
        session_number: Optional[int],
        summaries_timeline: List[Dict[str, Any]],
        open_tasks: List[Dict[str, Any]],
    ) -> SessionPrepBriefResult:
        """
        Generate a 4-section clinical prep brief using approved history + open tasks.

        summaries_timeline: all approved summaries ordered oldest â†’ newest (most recent last).
        open_tasks: all incomplete exercises/tasks for this patient.
        """
        if self.client is None:
            raise RuntimeError(
                "AI client not initialized. Set a valid OPENAI_API_KEY in .env."
            )

        has_summaries = bool(summaries_timeline)

        # â”€â”€ Build approved-summaries context â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if has_summaries:
            history_parts = []
            for s in summaries_timeline:
                date_str = str(s.get("session_date", "?"))
                num = s.get("session_number", "?")
                full_summary = s.get("full_summary", "") or ""
                topics = ", ".join(s.get("topics_discussed", []) or [])
                progress = s.get("patient_progress", "") or ""
                homework = ", ".join(s.get("homework_assigned", []) or [])
                risk = s.get("risk_assessment", "") or ""
                next_plan = s.get("next_session_plan", "") or ""
                summary_block = (
                    f'×¡×™×›×•× (×¢×¨×•×š ×¢"×™ ×”×ž×˜×¤×œ):\n{full_summary}\n' if full_summary else ""
                )
                history_parts.append(
                    f"--- ×¤×’×™×©×” #{num} ({date_str}) ---\n"
                    f"{summary_block}"
                    f"× ×•×©××™×: {topics}\n"
                    f"×”×ª×§×“×ž×•×ª: {progress}\n"
                    f"×ž×©×™×ž×•×ª ×‘×™×ª: {homework}\n"
                    f"×ª×•×›× ×™×ª ×œ×”×ž×©×š: {next_plan}\n"
                    f"×¡×™×›×•×Ÿ: {risk}"
                )
            summaries_context = (
                '×”×™×¡×˜×•×¨×™×™×ª ×”×¤×’×™×©×•×ª (×ž××•×©×¨×ª ×¢"×™ ×”×ž×˜×¤×œ, ×ž×”×™×©× ×” ×œ×—×“×©×”):\n\n'
                + "\n\n".join(history_parts)
            )
        else:
            summaries_context = "(××™×Ÿ ×¡×™×›×•×ž×™× ×ž××•×©×¨×™× ×¢×“×™×™×Ÿ)"

        # â”€â”€ Build open tasks context â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if open_tasks:
            tasks_lines = "\n".join(
                f"- {t.get('description', '')} (× ×•×¦×¨: {str(t.get('created_at', '?'))[:10]})"
                for t in open_tasks
            )
            tasks_context = f"×ž×©×™×ž×•×ª ×¤×ª×•×—×•×ª (×œ× ×”×•×©×œ×ž×•):\n{tasks_lines}"
        else:
            tasks_context = "×ž×©×™×ž×•×ª ×¤×ª×•×—×•×ª: ××™×Ÿ"

        session_num_str = f"#{session_number}" if session_number else ""

        if not has_summaries:
            no_history_note = (
                "\nâš ï¸ CRITICAL â€” NO HISTORY EXISTS FOR THIS PATIENT.\n"
                "There are ZERO approved session summaries in the database.\n"
                "You MUST NOT invent, fabricate, or guess any past sessions, topics, progress, "
                "homework, or clinical details. Any invented history is a serious clinical error.\n"
                "history_summary and last_session MUST state clearly that there is no history yet "
                "and that this appears to be the first documented session. "
                "focus_for_today should contain only general first-session guidance.\n"
            )
        else:
            no_history_note = ""

        prompt = f"""\
××ª×” ×¢×•×–×¨ ×§×œ×™× ×™ ××™×©×™ ×©×œ ×”×ž×˜×¤×œ. ×ª×¤×§×™×“×š ×œ×¡×›× ××ª ×”×”×™×¡×˜×•×¨×™×” ×”×§×œ×™× ×™×ª ×•×œ×”×›×™×Ÿ ××ª ×”×ž×˜×¤×œ ×œ×¤×’×™×©×” ×”×§×¨×•×‘×”.
××ª×” ×œ× ×ž××‘×—×Ÿ ×•×œ× ×ž×§×‘×œ ×”×—×œ×˜×•×ª ×˜×™×¤×•×œ×™×•×ª â€” ××ª×” ×ž××¨×’×Ÿ ××ª ×”×ž×™×“×¢ ×”×§×™×™× ×‘×¦×•×¨×” ×‘×¨×•×¨×” ×•×¤×¨×§×˜×™×ª.
{no_history_note}
×”×¤×’×™×©×” ×”×§×¨×•×‘×”: ×ž×˜×•×¤×œ "{patient_name}", ×¤×’×™×©×” {session_num_str}, ×‘×ª××¨×™×š {session_date}.

{summaries_context}

{tasks_context}

×”×—×–×¨ ×ª×©×•×‘×” **××š ×•×¨×§** ×›-JSON ×ª×§×™×Ÿ (×œ×œ× markdown, ×œ×œ× ```):
{{
  "history_summary": ["×ª×ž×”/×“×¤×•×¡ ×ž×¨×›×–×™ ×ž×›×œ ×”×”×™×¡×˜×•×¨×™×”", "×ž×’×ž×ª ×”×”×ª×§×“×ž×•×ª ×”×›×œ×œ×™×ª", "..."],
  "last_session": ["×ž×” ×¢×œ×” ×‘×¤×’×™×©×” ×”××—×¨×•× ×”", "×ž×” ×”×•×¡×›× / × ×•×ª×¨ ×¤×ª×•×—", "..."],
  "tasks_to_check": ["×ª×™××•×¨ ×ž×©×™×ž×” ×œ×‘×“×™×§×”", "..."],
  "focus_for_today": ["×”×¦×¢×” ×§×•× ×§×¨×˜×™×ª 1 ×œ×ž×” ×œ×©×™× ×“×’×©", "×”×¦×¢×” 2", "..."],
  "watch_out_for": ["×¡×™×›×•×Ÿ/×¨×’×™×©×•×ª ×× ×§×™×™×", "..."]
}}

×›×œ×œ×™×:
- history_summary: 2â€“3 ×¤×¨×™×˜×™× â€” ×ª×ž×•×ª ×•×“×¤×•×¡×™× ×—×•×¦×™-×¤×’×™×©×•×ª, ×œ× ×—×–×¨×” ×¢×œ ×›×œ ×¤×’×™×©×”.
  ×× ××™×Ÿ ×”×™×¡×˜×•×¨×™×” ×ž××•×©×¨×ª â€” ×›×ª×•×‘ ["××™×Ÿ ×¡×™×›×•×ž×™× ×ž××•×©×¨×™× ×¢×“×™×™×Ÿ â€” ×–×• ×›×›×œ ×”× ×¨××” ×”×¤×’×™×©×” ×”×¨××©×•× ×”"].
- last_session: 2â€“3 ×¤×¨×™×˜×™× â€” ×¡×¤×¦×™×¤×™ ×œ×¤×’×™×©×” ×”××—×¨×•× ×” ×‘×œ×‘×“.
  ×× ××™×Ÿ ×”×™×¡×˜×•×¨×™×” â€” ×›×ª×•×‘ ["××™×Ÿ ×¤×’×™×©×•×ª ×§×•×“×ž×•×ª ×ž×ª×•×¢×“×•×ª"].
- tasks_to_check: ×× ××™×Ÿ ×ž×©×™×ž×•×ª ×¤×ª×•×—×•×ª â€” ["××™×Ÿ ×ž×©×™×ž×•×ª ×¤×ª×•×—×•×ª"]. ××—×¨×ª â€” ×ž× ×” ××•×ª×Ÿ ×ª×ž×¦×™×ª×™×ª.
- focus_for_today: 2â€“3 ×”×¦×¢×•×ª ×¤×¨×§×˜×™×•×ª â€” ×ž×‘×•×¡×¡ ××š ×•×¨×§ ×¢×œ ×ž×™×“×¢ ×©× ×ž×¡×¨ ×œ×š. ×× ××™×Ÿ ×”×™×¡×˜×•×¨×™×” â€” ×”×¦×¢ ×’×™×©×” ×œ×¤×’×™×©×” ×¨××©×•× ×”.
- watch_out_for: ×¨×§ ×× ×™×© ×¡×™×›×•×Ÿ/×¨×’×™×©×•×ª ×ž×ž×©×™×™× ×‘× ×ª×•× ×™×. ××—×¨×ª â€” [].
- ××¡×•×¨ ×‘×”×—×œ×˜ ×œ×”×ž×¦×™× ×¤×’×™×©×•×ª, ×¤×¨×˜×™× ×§×œ×™× ×™×™×, ×ž×©×™×ž×•×ª, × ×•×©××™×, ××• ×›×œ ×ž×™×“×¢ ×©×œ× ×ž×•×¤×™×¢ ×‘×ž×¤×•×¨×© ×‘× ×ª×•× ×™× ×©× ×ž×¡×¨×•.
- ×›×ª×•×‘ ×‘×¢×‘×¨×™×ª ×ž×§×¦×•×¢×™×ª ×©×•×˜×¤×ª. ×ª×ž×¦×™×ª×™ â€” ×ž×˜×¤×œ ×¢×¡×•×§ ×§×•×¨× ××ª ×–×” ×‘-30 ×©× ×™×•×ª.
"""

        # Use low temperature for prep brief â€” factual retrieval, not creative generation.
        # For no-history patients this is critical to prevent hallucination.
        prep_temperature = 0.1

        try:
            raw = await self._generate_openai(prompt, temperature=prep_temperature)
            return self._parse_prep_brief_json(raw)

        except Exception as e:
            logger.error(f"Error generating session prep brief: {e}")
            raise

    def _parse_prep_brief_json(self, raw: str) -> SessionPrepBriefResult:
        """Parse AI response into SessionPrepBriefResult, with fallback."""
        cleaned = raw.strip()
        if cleaned.startswith("```"):
            cleaned = cleaned.split("\n", 1)[1] if "\n" in cleaned else cleaned[3:]
        if cleaned.endswith("```"):
            cleaned = cleaned[: cleaned.rfind("```")]
        cleaned = cleaned.strip()

        try:
            data = json.loads(cleaned)
        except json.JSONDecodeError:
            logger.warning("AI returned non-JSON prep brief, wrapping as fallback")
            return SessionPrepBriefResult(
                history_summary=[raw],
                last_session=[],
                tasks_to_check=[],
                focus_for_today=[],
                watch_out_for=[],
            )

        return SessionPrepBriefResult(
            history_summary=data.get("history_summary", []),
            last_session=data.get("last_session", []),
            tasks_to_check=data.get("tasks_to_check", []),
            focus_for_today=data.get("focus_for_today", []),
            watch_out_for=data.get("watch_out_for", []),
        )

    async def generate_deep_summary(
        self,
        patient_name: str,
        approved_summaries: List[Dict[str, Any]],
        all_tasks: List[Dict[str, Any]],
        metrics: Dict[str, Any],
        therapist_locale: str = "he",
    ) -> DeepSummaryResult:
        """
        Generate a comprehensive deep treatment summary.

        JSON keys are always English; text values are written in therapist_locale.
        approved_summaries: all approved summaries ordered oldest â†’ newest.
        all_tasks: open + completed tasks with status/dates.
        metrics: {total_sessions, first_session_date, last_session_date, long_gaps}.
        therapist_locale: ISO language code, e.g. "he" or "en".
        """
        if self.client is None:
            raise RuntimeError(
                "AI client not initialized. Set a valid OPENAI_API_KEY in .env."
            )

        locale_names: Dict[str, str] = {"he": "Hebrew", "en": "English"}
        output_language = locale_names.get(therapist_locale, therapist_locale)

        # â”€â”€ Summaries context â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if approved_summaries:
            summary_parts = []
            for s in approved_summaries:
                date_str = str(s.get("session_date", "?"))
                num = s.get("session_number", "?")
                full_summary = s.get("full_summary", "") or ""
                topics = ", ".join(s.get("topics_discussed", []) or [])
                progress = s.get("patient_progress", "") or ""
                homework = ", ".join(s.get("homework_assigned", []) or [])
                risk = s.get("risk_assessment", "") or ""
                summary_parts.append(
                    f"--- Session #{num} ({date_str}) ---\n"
                    f"Summary: {full_summary}\n"
                    f"Topics: {topics}\n"
                    f"Progress: {progress}\n"
                    f"Homework: {homework}\n"
                    f"Risk: {risk}"
                )
            summaries_context = (
                "Approved session summaries (oldest to newest):\n\n"
                + "\n\n".join(summary_parts)
            )
        else:
            summaries_context = "(No approved session summaries yet)"

        # â”€â”€ Tasks context â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        open_tasks = [t for t in all_tasks if not t.get("completed", False)]
        done_tasks = [t for t in all_tasks if t.get("completed", False)]
        tasks_lines = []
        for t in open_tasks:
            tasks_lines.append(
                f"  [OPEN] {t.get('description', '?')} "
                f"(assigned: {str(t.get('created_at', '?'))[:10]})"
            )
        for t in done_tasks:
            done_date = str(t.get("completed_at", "?"))[:10] if t.get("completed_at") else "?"
            tasks_lines.append(
                f"  [DONE] {t.get('description', '?')} (completed: {done_date})"
            )
        tasks_context = "Tasks:\n" + (
            "\n".join(tasks_lines) if tasks_lines else "  (no tasks recorded)"
        )

        # â”€â”€ Metrics context â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        total = metrics.get("total_sessions", "?")
        first_date = str(metrics.get("first_session_date", "?"))
        last_date = str(metrics.get("last_session_date", "?"))
        gaps = metrics.get("long_gaps", [])
        gaps_note = ""
        if gaps:
            gaps_note = "\nLong breaks (>30 days): " + "; ".join(
                f"{g['from']} to {g['to']} ({g['days']} days)" for g in gaps
            )
        metrics_context = (
            f"Total sessions: {total}\n"
            f"First session: {first_date}\n"
            f"Last session: {last_date}" + gaps_note
        )

        approved_count = len(approved_summaries)
        task_count = len(all_tasks)

        # â”€â”€ Strict data-constraint block (always included) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        data_constraints = (
            f"\nSTRICT DATA CONSTRAINTS â€” YOU MUST OBEY THESE EXACTLY:\n"
            f"- The data above contains exactly {approved_count} approved session summary(ies).\n"
            f"  Do NOT reference, invent, or imply any sessions beyond those shown.\n"
            f"- The task list above contains exactly {task_count} task(s).\n"
            f"  Do NOT mention any tasks, homework, or exercises not explicitly listed in the task list.\n"
        )
        if approved_count == 1:
            data_constraints += (
                "- There is only ONE session in the data. "
                "Do NOT use plural 'sessions', 'previous sessions', 'across sessions', "
                "'over multiple sessions', or any phrase implying more than one session.\n"
            )
        if approved_count == 0:
            data_constraints += (
                "- There are NO approved sessions. "
                "Every section must state that no session data is available.\n"
            )
        if task_count == 0:
            data_constraints += (
                "- There are NO tasks. "
                "The goals_and_tasks field must describe only the therapeutic focus areas visible "
                "in the session text. Do NOT invent or suggest tasks.\n"
            )

        prompt = f"""\
You are a clinical reflection assistant for the therapist. You synthesize and reflect â€” you do not diagnose, prescribe, or invent information.
{data_constraints}
Patient: "{patient_name}"

{summaries_context}

{tasks_context}

{metrics_context}
(Note: "Total sessions" above counts all scheduled sessions; only the {approved_count} approved \
summaries shown above are available as data â€” do not infer content from sessions without summaries.)

LANGUAGE REQUIREMENT: All text values MUST be written in {output_language}. \
JSON field names must remain exactly in English as shown below.

Return ONLY valid JSON (no markdown fences, no text outside JSON):
{{
  "overall_treatment_picture": "2-3 paragraphs summarising the main themes visible in the approved session summaries. If there is only one session, summarise that single session without implying prior history.",
  "timeline_highlights": ["key observation or moment from the data â€” only from sessions listed above"],
  "goals_and_tasks": "Describe the therapeutic focus areas visible in the session text. List ONLY the tasks that appear in the task list above â€” if none, state that no tasks have been defined.",
  "measurable_progress": "Concrete examples of change visible in the session summaries. If only one session exists, describe what was observed in that session without comparing to non-existent prior sessions.",
  "directions_for_next_phase": "2-3 suggested directions for the next phase, based solely on the data above."
}}

Rules:
- Base everything ONLY on the data provided above. Do NOT invent sessions, tasks, or details.
- timeline_highlights: 1-3 items when there is only 1 session; up to 6 items for 5+ sessions.
- No clinical diagnoses, no medication suggestions.
- All text values in {output_language}. JSON keys must be English.
"""

        try:
            raw = await self._generate_openai(prompt)
            return self._parse_deep_summary_json(raw)
        except Exception as e:
            logger.error(f"Error generating deep summary: {e}")
            raise

    def _parse_deep_summary_json(self, raw: str) -> DeepSummaryResult:
        """Parse AI response into DeepSummaryResult, with fallback."""
        cleaned = raw.strip()
        if cleaned.startswith("```"):
            cleaned = cleaned.split("\n", 1)[1] if "\n" in cleaned else cleaned[3:]
        if cleaned.endswith("```"):
            cleaned = cleaned[: cleaned.rfind("```")]
        cleaned = cleaned.strip()

        try:
            data = json.loads(cleaned)
        except json.JSONDecodeError:
            logger.warning("AI returned non-JSON deep summary, wrapping as fallback")
            return DeepSummaryResult(
                overall_treatment_picture=raw,
                timeline_highlights=[],
                goals_and_tasks="",
                measurable_progress="",
                directions_for_next_phase="",
            )

        return DeepSummaryResult(
            overall_treatment_picture=data.get("overall_treatment_picture", ""),
            timeline_highlights=data.get("timeline_highlights", []),
            goals_and_tasks=data.get("goals_and_tasks", ""),
            measurable_progress=data.get("measurable_progress", ""),
            directions_for_next_phase=data.get("directions_for_next_phase", ""),
        )

    async def generate_treatment_plan_preview(
        self,
        patient_name: str,
        approved_summaries: List[Dict[str, Any]],
        all_tasks: List[Dict[str, Any]],
        therapist_locale: str = "he",
    ) -> TreatmentPlanResult:
        """
        Generate a treatment plan preview (goals, focus areas, interventions) from history.

        JSON keys are always English; text values are written in therapist_locale.
        """
        if self.client is None:
            raise RuntimeError(
                "AI client not initialized. Set a valid OPENAI_API_KEY in .env."
            )

        locale_names: Dict[str, str] = {"he": "Hebrew", "en": "English"}
        output_language = locale_names.get(therapist_locale, therapist_locale)

        # â”€â”€ Summaries context â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if approved_summaries:
            summary_parts = []
            for s in approved_summaries:
                date_str = str(s.get("session_date", "?"))
                num = s.get("session_number", "?")
                full_summary = s.get("full_summary", "") or ""
                topics = ", ".join(s.get("topics_discussed", []) or [])
                progress = s.get("patient_progress", "") or ""
                homework = ", ".join(s.get("homework_assigned", []) or [])
                summary_parts.append(
                    f"--- Session #{num} ({date_str}) ---\n"
                    f"Summary: {full_summary}\n"
                    f"Topics: {topics}\n"
                    f"Progress: {progress}\n"
                    f"Homework: {homework}"
                )
            summaries_context = (
                "Approved session summaries (chronological):\n\n"
                + "\n\n".join(summary_parts)
            )
        else:
            summaries_context = "(No approved session summaries yet)"

        # â”€â”€ Tasks context â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        open_tasks = [t for t in all_tasks if not t.get("completed", False)]
        done_tasks = [t for t in all_tasks if t.get("completed", False)]
        tasks_lines = []
        for t in open_tasks:
            tasks_lines.append(f"  [OPEN] {t.get('description', '?')}")
        for t in done_tasks:
            tasks_lines.append(f"  [DONE] {t.get('description', '?')}")
        tasks_context = "Tasks:\n" + (
            "\n".join(tasks_lines) if tasks_lines else "  (none)"
        )

        limited_data_note = ""
        if len(approved_summaries) < 2:
            limited_data_note = (
                "\nNOTE: Very few approved summaries â€” infer conservatively "
                "and note the limitation in goal descriptions.\n"
            )

        prompt = f"""\
You are a clinical planning assistant for the therapist. You draft a treatment plan \
from the session history â€” you do not diagnose or invent information not present in the data.
{limited_data_note}
Patient: "{patient_name}"

{summaries_context}

{tasks_context}

LANGUAGE REQUIREMENT: All text values MUST be written in {output_language}. \
JSON keys must remain exactly in English as shown.

Return ONLY valid JSON (no markdown, no text outside JSON):
{{
  "goals": [
    {{"id": "g1", "title": "Short goal title", "description": "1-2 sentences about this goal, why it matters, how it appears in the session data."}},
    {{"id": "g2", "title": "...", "description": "..."}}
  ],
  "focus_areas": ["main theme/domain 1", "main theme/domain 2", "..."],
  "suggested_interventions": ["intervention type or homework idea 1 (must be grounded in existing data)", "..."]
}}

Rules:
- goals: 3-5 items. IDs must be "g1", "g2", etc. Infer only from the history.
- focus_areas: 3-6 thematic domains to work on.
- suggested_interventions: based ONLY on interventions/tasks already in the data, not generic ideas.
- No clinical diagnoses, no medication suggestions.
- All text values in {output_language}. JSON keys must be English.
"""

        try:
            raw = await self._generate_openai(prompt)
            return self._parse_treatment_plan_json(raw)
        except Exception as e:
            logger.error(f"Error generating treatment plan preview: {e}")
            raise

    def _parse_treatment_plan_json(self, raw: str) -> TreatmentPlanResult:
        """Parse AI response into TreatmentPlanResult, with fallback."""
        cleaned = raw.strip()
        if cleaned.startswith("```"):
            cleaned = cleaned.split("\n", 1)[1] if "\n" in cleaned else cleaned[3:]
        if cleaned.endswith("```"):
            cleaned = cleaned[: cleaned.rfind("```")]
        cleaned = cleaned.strip()

        try:
            data = json.loads(cleaned)
        except json.JSONDecodeError:
            logger.warning("AI returned non-JSON treatment plan, using empty fallback")
            return TreatmentPlanResult(goals=[], focus_areas=[], suggested_interventions=[])

        goals_raw = data.get("goals", [])
        goals = [
            TreatmentGoal(
                id=str(g.get("id", f"g{i + 1}")),
                title=g.get("title", ""),
                description=g.get("description", ""),
            )
            for i, g in enumerate(goals_raw)
            if isinstance(g, dict)
        ]

        return TreatmentPlanResult(
            goals=goals,
            focus_areas=data.get("focus_areas", []),
            suggested_interventions=data.get("suggested_interventions", []),
        )

    async def generate_today_insights(
        self,
        patients_context: List[Dict[str, Any]],
        therapist_locale: str = "he",
    ) -> TodayInsightsResult:
        """
        Generate smart per-patient reminders for today's sessions.

        patients_context: list of dicts with keys:
            patient_id, patient_name, session_number, approved_summaries, open_tasks
        therapist_locale: ISO language code ("he" or "en").

        Makes ONE AI call for all patients combined.
        Returns TodayInsightsResult with one item per patient.
        """
        if self.client is None:
            raise RuntimeError(
                "AI client not initialized. Set a valid OPENAI_API_KEY in .env."
            )

        if not patients_context:
            return TodayInsightsResult(insights=[])

        locale_names: Dict[str, str] = {"he": "Hebrew", "en": "English"}
        output_language = locale_names.get(therapist_locale, therapist_locale)

        # Build compact per-patient context block
        patient_blocks = []
        for p in patients_context:
            pid = p.get("patient_id", "?")
            name = p.get("patient_name", "?")
            session_num = p.get("session_number")
            session_label = f"Session #{session_num}" if session_num else "Session"
            summaries = p.get("approved_summaries", [])
            tasks = p.get("open_tasks", [])

            block_lines = [f"[patient_id={pid}] {name} â€” {session_label} today"]

            if summaries:
                for s in summaries:
                    date_str = str(s.get("session_date", "?"))
                    num = s.get("session_number", "?")
                    full = (s.get("full_summary", "") or "")[:300]
                    topics = ", ".join(s.get("topics_discussed", []) or [])
                    progress = s.get("patient_progress", "") or ""
                    line = f"  Session #{num} ({date_str}): {full}"
                    if topics:
                        line += f" | Topics: {topics}"
                    if progress:
                        line += f" | Progress: {progress}"
                    block_lines.append(line)
            else:
                block_lines.append("  (no approved summaries yet)")

            if tasks:
                task_list = "; ".join(t.get("description", "") for t in tasks[:5])
                block_lines.append(f"  Open tasks: {task_list}")
            else:
                block_lines.append("  Open tasks: none")

            patient_blocks.append("\n".join(block_lines))

        context_str = "\n\n".join(patient_blocks)

        prompt = f"""\
You are a clinical preparation assistant. The therapist has sessions scheduled today. \
For each patient listed, write one concise smart reminder (title + body) to help the \
therapist enter the session prepared.

LANGUAGE REQUIREMENT: All text values MUST be written in {output_language}. \
JSON keys must remain exactly in English as shown.

Return ONLY valid JSON (no markdown fences, no text outside JSON):
{{
  "insights": [
    {{"patient_id": <integer>, "title": "concise title â€” max 8 words", "body": "1-2 practical sentences based only on the data below"}}
  ]
}}

Rules:
- Include EVERY patient listed below (one item per patient).
- title: max 8 words â€” the single most important thing to remember.
- body: 1-2 short sentences. Practical and specific. Based ONLY on the session data provided.
- If there is no prior data for a patient: title = "First session" (in {output_language}), body = encourage an open intake approach.
- No clinical diagnoses. No medication suggestions.
- All text values in {output_language}. JSON keys must stay in English.

Today's patients:
{context_str}
"""

        try:
            raw = await self._generate_openai(prompt)
            return self._parse_today_insights_json(raw)
        except Exception as e:
            logger.error(f"Error generating today insights: {e}")
            raise

    def _parse_today_insights_json(self, raw: str) -> TodayInsightsResult:
        """Parse AI response into TodayInsightsResult, with fallback."""
        cleaned = raw.strip()
        if cleaned.startswith("```"):
            cleaned = cleaned.split("\n", 1)[1] if "\n" in cleaned else cleaned[3:]
        if cleaned.endswith("```"):
            cleaned = cleaned[: cleaned.rfind("```")]
        cleaned = cleaned.strip()

        try:
            data = json.loads(cleaned)
        except json.JSONDecodeError:
            logger.warning("AI returned non-JSON today insights, returning empty")
            return TodayInsightsResult(insights=[])

        items = []
        for item in data.get("insights", []):
            if isinstance(item, dict) and "patient_id" in item:
                try:
                    items.append(
                        TodayInsightItem(
                            patient_id=int(item["patient_id"]),
                            title=item.get("title", ""),
                            body=item.get("body", ""),
                        )
                    )
                except (ValueError, TypeError):
                    pass

        return TodayInsightsResult(insights=items)

    async def _generate_openai(self, prompt: str, temperature: Optional[float] = None) -> str:
        """Generate response using OpenAI. Pass temperature to override the profile default."""
        response = await self.client.chat.completions.create(
            model=settings.AI_MODEL,
            messages=[
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": prompt}
            ],
            temperature=temperature if temperature is not None else settings.TEMPERATURE,
            max_tokens=settings.MAX_TOKENS,
        )
        return response.choices[0].message.content

    async def handle_command(self, command: str, args: str = "") -> str:
        """
        Handle special commands like /start, /summary, etc.

        Args:
            command: The command (without /)
            args: Optional arguments

        Returns:
            Command response
        """
        command_handlers = {
            "start": self._handle_start,
            "summary": self._handle_summary,
            "client": self._handle_client,
            "message": self._handle_message,
            "templates": self._handle_templates,
            "status": self._handle_status,
            "privacy": self._handle_privacy,
        }

        handler = command_handlers.get(command)
        if handler:
            return await handler(args)
        else:
            return f"×¤×§×•×“×” ×œ× ×ž×•×›×¨×ª: /{command}"

    async def _handle_start(self, args: str) -> str:
        """Handle /start command - onboarding"""
        return """
×©×œ×•×! ×× ×™ **TherapyCompanion.AI** - ×”×¡×•×›×Ÿ ×”××™×©×™ ×©×œ×š.
×× ×™ ×›××Ÿ ×›×“×™ ×œ×—×¡×•×š ×œ×š ×–×ž×Ÿ ×•×œ×©×ž×•×¨ ×¢×œ ×§×©×¨ ×¢× ×”×ž×˜×•×¤×œ×™× ×©×œ×š ×‘×™×Ÿ ×”×¤×’×™×©×•×ª.

×›×“×™ ×œ×”×ª×—×™×œ, ×‘×•××• × ×›×™×¨:
1. ×¡×¤×¨/×™ ×œ×™ ×¢×œ ×”×’×™×©×” ×”×˜×™×¤×•×œ×™×ª ×©×œ×š (CBT, ×¤×¡×™×›×•×“×™× ×ž×™×ª ×•×›×•')
2. ××™×š ××ª/×” ×‘×“×¨×š ×›×œ×œ ×›×•×ª×‘/×ª ×¡×™×›×•×ž×™×?
3. ×ž×” ×”×˜×•×Ÿ ×”×ž×•×¢×“×£ ×©×œ×š ×œ×”×•×“×¢×•×ª ×œ×ž×˜×•×¤×œ×™×?
4. ×™×© ×ž×˜×•×¤×œ×™× ×¡×¤×¦×™×¤×™×™× ×©×ª×¨×¦×”/×™ ×©××¢×§×•×‘ ××—×¨×™×”×?

××—×¨×™ ×–×” ×× ×™ ×™×›×•×œ ×œ×”×ª×—×™×œ ×œ×¢×–×•×¨ ×œ×š ×ž×™×“ :)
"""

    async def _handle_summary(self, args: str) -> str:
        """Handle /summary command - create session summary"""
        return "×‘×•××• × ×™×¦×•×¨ ×¡×™×›×•× ×¤×’×™×©×”. ××¤×©×¨ ×œ×”×§×œ×™×˜, ×œ×”×§×œ×™×“, ××• ×œ×¡×¤×§ ×˜×§×¡×˜."

    async def _handle_client(self, args: str) -> str:
        """Handle /client command - open patient profile"""
        if not args:
            return "×× × ×¦×™×™×Ÿ/×™ ×©× ×ž×˜×•×¤×œ. ×©×™×ž×•×©: /client [×©×]"
        return f"×¤×•×ª×— ×¤×¨×•×¤×™×œ ×ž×˜×•×¤×œ: {args}"

    async def _handle_message(self, args: str) -> str:
        """Handle /message command - create message for patient"""
        if not args:
            return "×× × ×¦×™×™×Ÿ/×™ ×©× ×ž×˜×•×¤×œ. ×©×™×ž×•×©: /message [×©×]"
        return f"×™×•×¦×¨ ×”×•×“×¢×” ×œ×ž×˜×•×¤×œ: {args}"

    async def _handle_templates(self, args: str) -> str:
        """Handle /templates command - manage templates"""
        return "× ×™×”×•×œ ×ª×‘× ×™×•×ª ××™×©×™×•×ª"

    async def _handle_status(self, args: str) -> str:
        """Handle /status command - show all patients status"""
        return "×ž×¦×‘ ×›×œ ×”×ž×˜×•×¤×œ×™×"

    async def _handle_privacy(self, args: str) -> str:
        """Handle /privacy command - privacy settings"""
        return "×”×’×“×¨×•×ª ×¤×¨×˜×™×•×ª ×•××‘×˜×—×”"
